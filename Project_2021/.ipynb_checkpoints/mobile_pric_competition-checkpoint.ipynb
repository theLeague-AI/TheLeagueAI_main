{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this modern era, smartphones are an integral part of the lives of human beings. When a smartphone is purchased, many factors like the display, processor, memory, camera, thickness, battery, connectivity and others are taken into account. One factor that people do not consider is whether the product is worth the cost. As there are no resources to cross-validate the price, people fail in taking the correct decision.\n",
    "\n",
    "This project intends to solve this issue by taking the historical data pertaining to the key features of smartphones along with its cost and develop a model that will predict the approximate price of the new smartphone with a reasonable accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "A reminder of the general approach to working on a Machine Lerning Project:</p>\n",
    "<ul>\n",
    " \n",
    "    1. Start off by loading and viewing the dataset. Make sure you are able to understand the how our data looks, the data types and value ranges.\n",
    " \n",
    "    2. Prepare the data to make sure that you are not missing any values and that your data is ready for your ML model to make predictions.\n",
    " \n",
    "    3. Build some intuition on your data by exploring the features.\n",
    " \n",
    "    4. Finally build a machine learning model that can predict if an individual's application for a credit card will be accepted.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- The data is sitting on a csv file named train_mobil_data.csv\n",
    "- The features present in this data are:\n",
    "\n",
    "    * id:ID\n",
    "    * battery_power:Total energy a battery can store in one time measured in mAh\n",
    "    * blue:Has bluetooth or not\n",
    "    * clock_speed:speed at which microprocessor executes instructions\n",
    "    * dual_sim:Has dual sim support or not\n",
    "    * fc:Front Camera mega pixels\n",
    "    * four_g:Has 4G or not\n",
    "    * int_memory:Internal Memory in Gigabytes\n",
    "    * m_dep:Mobile Depth in cm\n",
    "    * mobile_wt:Weight of mobile phone\n",
    "    * n_cores:Number of cores of processor\n",
    "    * pc:Primary Camera mega pixels\n",
    "    * px_height:Pixel Resolution Height\n",
    "    * px_width:Pixel Resolution Width\n",
    "    * ram:Random Access Memory in Megabytes\n",
    "    * sc_h:Screen Height of mobile in cm\n",
    "    * sc_w:Screen Width of mobile in cm\n",
    "    * talk_time:longest time that a single battery charge will last when you are\n",
    "    * three_g:Has 3G or not\n",
    "    * touch_screen:Has touch screen or not\n",
    "    * wifi:Has wifi or not\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "Load the data from the file provided and inspect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "dataset=pd.read_csv('../input/train.csv')\n",
    "\n",
    "# Inspect data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "This is the process where you look at and understand their data with statistical and visualization methods. This step helps identifying patterns and problems in the dataset, as well as deciding which model or algorithm to use in subsequent steps.\n",
    "\n",
    "The steps you should consider in this stage include:\n",
    "\n",
    "- Identify input(features) and output(target) variables on your data\n",
    "- Identify the types of data\n",
    "- identify categorical vs continuous variables\n",
    "- Understanding the statistical properties of your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code for data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "e now have a basic idea about the data. We need to extend that with some visualizations.\n",
    "\n",
    "We are going to look at two types of plots:\n",
    "\n",
    "- Histograms plot to have an idea of the distribution\n",
    "- Scatter plots to find some of the correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "You must now begin the process of transforming raw data so that data it is run through your ml model\n",
    "\n",
    "- Modify the data types of each feature (if needed)\n",
    "- Look for missing values, replace or remove\n",
    "- Modify skewed variables\n",
    "- Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enngineering\n",
    "You must now begin the process of extracting more information from existing data. You are not adding any new data here, but you are actually making the data you already have more useful.\n",
    "\n",
    "\n",
    "The steps you should consider in this stage include:\n",
    "\n",
    "- Developing new features apart from those already generated\n",
    "\n",
    "- Selecting a set of features to remove\n",
    "\n",
    "- Creating features using existing data through mathematical operations \n",
    "\n",
    "- Applying feature scaling\n",
    "\n",
    "- Applying label encoding\n",
    "\n",
    "- Understanding correlation between features and target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Train and Test\n",
    "For training a model we initially split the model into 3 three sections which are ‘Training data’ ,‘Validation data’ and ‘Testing data’.\n",
    "You train the classifier using ‘training data set’, tune the parameters using ‘validation set’ and then test the performance of your classifier on unseen ‘test data set’. \n",
    "\n",
    "- Note: during training the classifier only the training and/or validation set is available. The test data set must not be used during training the classifier. The test set will only be available during testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "Now that the data has been processed it is time to determine the what model will be used to find our predictions. \n",
    "\n",
    "Consider the following points before making a choosing a model:\n",
    "\n",
    "- The type of prediction this project requires (classification/regression)\n",
    "- How well do you understand the model you want to use.\n",
    "- Previoous performance of the model you choose on similar data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and Accuracy Metrics\n",
    "<p>But how well does our model perform? </p>\n",
    "<p>We will now evaluate our model on the test set with respect to <a href=\"https://developers.google.com/machine-learning/crash-course/classification/accuracy\">classification accuracy</a>. But we will also take a look the model's <a href=\"http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\">confusion matrix</a>. In the case of predicting credit card applications, it is equally important to see if our machine learning model is able to predict the approval status of the applications as denied that originally got denied. If our model is not performing well in this aspect, then it might end up approving the application that should have been approved. The confusion matrix helps us to view our model's performance from these aspects.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Accuracy metrics code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Model Performance\n",
    "\n",
    "<p>Our model was pretty good! It was able to yield an accuracy score of almost 84%.</p>\n",
    "<p>For the confusion matrix, the first element of the of the first row of the confusion matrix denotes the true negatives meaning the number of negative instances (denied applications) predicted by the model correctly. And the last element of the second row of the confusion matrix denotes the true positives meaning the number of positive instances (approved applications) predicted by the model correctly.</p>\n",
    "\n",
    "<p>\n",
    "<ul>\n",
    "<li>tol</li>\n",
    "<li>max_iter</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
