{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"the_leagueAI_Logo.png\" alt=\"the_leagueAI_Logo\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "The Banana Company Inc. is a new mobile phone company wanting to disrupt the mobile phone business. Banana wants to compete with Apple and get in on this competitive market. However, since they are brand new to the game, they are seeking a Machine Learning Engineer (that’s YOU!) to help them estimate the most optimal price to sell their mobile phones. \n",
    "\n",
    "Today Banana Inc. will provide you a dataset containing smartphones design features and their cost from different phone manufacturers. The goal is to build a model that can estimate the price of any given phone based on the phone features. Having a machine learning model that can estimate the price range of any phone will give Banana Inc. a strategic advantage when deciding how to price their own phones. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"phones_image.jpeg\" alt=\"phones_image\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "Banana Inc. has been able to gather information on the technical features and cost of several competitors smartphones. The features gathered for each of these phones are described below:\n",
    "\n",
    "Features:\n",
    "   - ***id***: Identifies every single phone record available in our dataset\n",
    "   - ***battery_power***: Indicates the total energy a battery can store at once (measured in mAh)\n",
    "   - ***blue***: Indicates whether or not the phone has bluetooth capabilities\n",
    "   - ***clock_speed***: Indicates the speed at which the microprocessor executes instructions\n",
    "   - ***dual_sim***: Indicates whether or not the phone has dual sim support\n",
    "   - ***fc***: Indicates the number of megapixels available in the front camera\n",
    "   - ***four_g***: Indicates whether or not the phone has 4G capabilities\n",
    "   - ***int_memory***: Indicates the phone internal memory in Gigabytes\n",
    "   - ***m_dep***: Indicates the phone’s depth in cm\n",
    "   - ***mobile_wt***: Indicates the phone’s weight \n",
    "   - ***n_cores***: Indicates the number of cores the processor contains\n",
    "   - ***pc***: Indicates the number of mega pixels available in the phone’s primary camera mega pixels\n",
    "   - ***px_height***: Indicates the screen’s vertical pixel resolution\n",
    "   - ***px_width***: Indicates the screen’s horizontal pixel resolution\n",
    "   - ***ram***: Indicates the phone’s available ram\n",
    "   - ***sc_h***: Indicates the phone’s height in centimeters\n",
    "   - ***sc_w***: Indicates the phone’s width in centimeters\n",
    "   - ***talk_time***: Indicates the maximum call time that the phone’s battery will last on a single charge\n",
    "   - ***three_g***: Indicates whether or not the phone has 3G capabilities\n",
    "   - ***touch_screen***: Indicates whether or not the phone has a touch screen\n",
    "   - ***wifi***: Indicates whether or not the phone has wi-fi capabilities\n",
    "\n",
    "Target:\n",
    "   - ***price_range***: The price category for each phone. The different categories are explained using the table below:\n",
    "   \n",
    "| price_range Value | Range Description | Dollar Value Range |\n",
    "| --- | --- | --- |\n",
    "| 0 | Budget - Midrange | 0-699 | \n",
    "|  |  |  |\n",
    "| 1 | Premium - Flagship | 700-1300 | \n",
    "\n",
    "   \n",
    "   \n",
    "   \n",
    "Notes to Concider:\n",
    "- The data provided to you is sitting on a csv file named mobile_data_raw.csv\n",
    "- This data was gathered manually and therefore might have a lot of issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Objective:\n",
    "\n",
    "***To build a machine learning model that is capable of predicting the price range of a smartphone when provided the technical specifications (features) of that phone.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Approach:\n",
    "Remember of the general approach to working on a Machine Learning Project:\n",
    "\n",
    " \n",
    "    1. Start off by loading and viewing the dataset. Make sure to get a general understanding of how the data looks (data types, numerical range, ect.)\n",
    " \n",
    "    2. Prepare the data to make sure that you are not missing any values and that your data will be digested by your machine learning model as expected.\n",
    "    \n",
    "    3. Build some intuition on your data by exploring the features. Understand how your features will ultimately help your ml model make a prediction using the context of the problem.\n",
    " \n",
    "    4. Finally build the machine learning model and test its accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Load \n",
    "Load the data from the file provided and inspect it.\n",
    "\n",
    "---\n",
    "\n",
    "Steps to concider:\n",
    "- Start by importing the modules and packages that you might be using in this project\n",
    "- When importing the data concider the use of dataframes to store your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "mobiles_df=pd.read_csv('./train_mobile_data.csv')\n",
    "\n",
    "# Inspect data\n",
    "mobiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobiles_df.value_counts('price_range')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Exploration & Data Visualization\n",
    "Attempt to understand the data with statistical and visualization methods. This step will help you identify patterns and problems in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "The steps you should consider in this stage include:\n",
    "\n",
    "- Identify input(features) and output(target) variables on your data\n",
    "- What is the size of our data (data shape)\n",
    "- Identify the data types of each one of the features\n",
    "- Identify the number missing values on each feature\n",
    "- Identify categorical vs continuous(numerical) variables\n",
    "- Understand the statistical properties each feature\n",
    "- Creating histograms plot to have an idea of the distribution\n",
    "- Creating scatter plots to find some of the correlation between variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variables\n",
    "features = dataset.drop('price_range',axis=1)\n",
    "target = dataset['price_range']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print our data shape\n",
    "print('the shape of the feature dataset is ', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code for data exploration\n",
    "dataset.info()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for empty values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we must group the dataset by Pclass and Survived to gather the total count\n",
    "group = titanic_data.groupby(['pclass', 'survived'])\n",
    "pclass_survived = group.size().unstack()\n",
    "\n",
    "\n",
    "# Creating a histogram of age by survival\n",
    "hist = px.histogram(titanic_data,x = \"age\", opacity = 0.7, color = \"survived\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "categorical_columns = [\"name\",\"sex\",\"cabin\",\"embarked\", \"home.dest\"]\n",
    "numerical_columns = [\"pclass\",\"survived\",\"age\",\"sibsp\",\"parch\",\"ticket\",\"fare\",\"boat\",\"body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"For column {}, the values are: \\n{} \\n\".format(column, titanic_data[column].value_counts()))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    if col in [\"pclass\",\"survived\",\"sibsp\",\"parch\"]:\n",
    "        titanic_data.hist(column=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### MORE EXAMPLES WE CAN USE ####\n",
    "\n",
    "\n",
    "# Code for data visualization\n",
    "#sns.pairplot(dataset,hue='price_range')\n",
    "\n",
    "# how is price affected by ram?\n",
    "sns.jointplot(x='ram',y='price_range',data=dataset,color='red',kind='kde');\n",
    "\n",
    "# how is price affected by internam memory\n",
    "sns.pointplot(y=\"int_memory\", x=\"price_range\", data=dataset)\n",
    "\n",
    "# % percentage of phones wich support 3G\n",
    "labels = [\"3G-supported\",'Not supported']\n",
    "values=dataset['three_g'].value_counts().values\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(values, labels=labels, autopct='%1.1f%%',shadow=True,startangle=90)\n",
    "plt.show()\n",
    "\n",
    "# % percentage of phones that support 4G\n",
    "labels4g = [\"4G-supported\",'Not supported']\n",
    "values4g = dataset['four_g'].value_counts().values\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(values4g, labels=labels4g, autopct='%1.1f%%',shadow=True,startangle=90)\n",
    "plt.show()\n",
    "\n",
    "# How is price affected by battery power\n",
    "sns.boxplot(x=\"price_range\", y=\"battery_power\", data=dataset)\n",
    "\n",
    "# No of phones vs camera megapiles of front and primary camera\n",
    "plt.figure(figsize=(10,6))\n",
    "dataset['fc'].hist(alpha=0.5,color='blue',label='Front camera')\n",
    "dataset['pc'].hist(alpha=0.5,color='red',label='Primary camera')\n",
    "plt.legend()\n",
    "plt.xlabel('MegaPixels')\n",
    "\n",
    "# Talk time vs price range\n",
    "sns.pointplot(y=\"talk_time\", x=\"price_range\", data=dataset)\n",
    "\n",
    "\n",
    "\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Data Preparation\n",
    "You must now begin the process of transforming raw data so that data it is run through your ml model\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "- Modify the data types of each feature (if needed)\n",
    "- Look for missing values, replace or remove\n",
    "- Modify skewed variables\n",
    "- Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Look for missing values, replace or remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "# import seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "# calculate percentiles\n",
    "age_percentiles = np.percentile(titanic_data['age'], [25, 50, 75])\n",
    "\n",
    "# Print the result\n",
    "print(age_percentiles)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature Engineering\n",
    "You must now begin the process of extracting more information from existing data. You are not adding any new data here, but you are actually making the data you already have more useful.\n",
    "\n",
    "---\n",
    "\n",
    "The steps you should consider in this stage include:\n",
    "\n",
    "- Developing new features apart from those already generated\n",
    "\n",
    "- Selecting a set of features to remove\n",
    "\n",
    "- Creating features using existing data through mathematical operations \n",
    "\n",
    "- Applying feature scaling\n",
    "\n",
    "- Applying label encoding\n",
    "\n",
    "- Understanding correlation between features and target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Building the Model\n",
    "\n",
    "Now that the data has been processed it is time to determine and build the model that will be used to find our predictions. \n",
    "\n",
    "---\n",
    "\n",
    "Consider the following points before making a choosing a model:\n",
    "\n",
    "- Create a train and test sets of data from the provided data\n",
    "- The type of prediction this project requires (classification/regression)\n",
    "- Determine the best features to used based on feature importance\n",
    "- Define your model and modify it's parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For tree Visualization as kaggle does't support pydotplus just install the pydotplus in your systems's conda terminal\n",
    "'''\n",
    "feature_names=['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
    "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
    "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
    "       'touch_screen', 'wifi']\n",
    "       \n",
    "import pydotplus as pydot\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "dot_data = StringIO()\n",
    "\n",
    "tree.export_graphviz(dtree, out_file=dot_data,feature_names=feature_names)\n",
    "\n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())\n",
    "\n",
    "Image(graph.create_png())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_weights = model.feature_importances_\n",
    "feature_weights\n",
    "\n",
    "# Show top 5 features \n",
    "indices = np.argsort(feature_weights)[::-1]\n",
    "columns = X_train.columns.values[indices[:5]]\n",
    "values = feature_weights[indices][:5]\n",
    "\n",
    "# Creat the plot\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "plt.title(\"Normalized Weights for First Five Most Predictive Features\", fontsize=16)\n",
    "plt.bar(np.arange(5), values, width=0.6, align=\"center\", color='#00A000', \\\n",
    "       label=\"Feature Weight\")\n",
    "plt.bar(np.arange(5) - 0.3, np.cumsum(values), width=0.2, align=\"center\", color='#00A0A0', \\\n",
    "       label=\"Cumulative Feature Weight\")\n",
    "plt.xticks(np.arange(5), columns)\n",
    "plt.xlim((-0.5, 4.5))\n",
    "plt.ylabel(\"Weight\", fontsize=12)\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.33, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Code to build the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "dtree.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Accuracy Metrics\n",
    "With the model finally completed, it is time to understand the model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "Consider the following points before making a choosing a model:\n",
    "\n",
    "- Import the modules that will allow you to estimate different accuracy metrics\n",
    "- Determine the number of positive and negative predictions.\n",
    "- Make an assessment of what our results tell us and draw conclusions based on your findings \n",
    "- Provide and display your results using appropriate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Accuracy metrics code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=confusion_matrix(y_test,pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(matrix,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Find the accuracy of your predictions\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(test_accuracy)\n",
    "\n",
    "\n",
    "# lets save the number of accurate predictions in a variable\n",
    "pass_in_test = y_test.count()\n",
    "print('The number of passengers in our test dataset was', pass_in_test)\n",
    "\n",
    "titanic_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(titanic_confusion_matrix)print('The number of passengers which our model accurately predicted would survive/not survive was', test_accuracy*pass_in_test)\n",
    "\n",
    "\n",
    "titanic_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(titanic_confusion_matrix)\n",
    "\n",
    "\n",
    "# visualize the confusion matrix\n",
    "plt.figure(figsize = (5,3))\n",
    "sns.heatmap(titanic_confusion_matrix)\n",
    "\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
