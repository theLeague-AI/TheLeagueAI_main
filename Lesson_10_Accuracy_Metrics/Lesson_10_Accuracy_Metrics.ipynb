{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 10 - Accuracy Metrics\n",
    "Welcome to the Accuracy Metrics. In this lesson we will be covering: \n",
    "- **Metrics for Classification**\n",
    "- **Metrics for Regression**\n",
    "\n",
    "The lab for Lesson 10 will consist of all the exercises throughtout the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lesson we will again be using the Titanic Survival Dataset from Kaggle to predict survival of passengers.\n",
    "\n",
    "Let's review the column values once more as a reminder of the data we are using:\n",
    "\n",
    "- **Survived**: Outcome of survival (0 = No; 1 = Yes)\n",
    "- **Pclass**: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)\n",
    "- **Name**: Name of passenger\n",
    "- **Sex**: Sex of the passenger\n",
    "- **Age**: Age of the passenger (Some entries contain ?)\n",
    "- **SibSp**: Number of siblings and spouses of the passenger aboard\n",
    "- **Parch**: Number of parents and children of the passenger aboard\n",
    "- **Ticket**: Ticket number of the passenger\n",
    "- **Fare**: Fare paid by the passenger\n",
    "- **Cabin**: Cabin number of the passenger (Some entries contain ?)\n",
    "- **Embarked**: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- **Boat**: Lifeboat (if survived)\n",
    "- **Body**: Body Number (if did not survive and body was recovered)\n",
    "- **Home.Dest**: Home / Destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have the Scikit-learn, please install using by removing the # from the conda command. \n",
    "# If you do not need to, then you can skip this step\n",
    "#!conda install -c anaconda scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your model ML - End to End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our lab today, we will go through end to end of the machine learning process to reiterate concepts we have learned, and then discuss ones that we learned today. \n",
    "\n",
    "Lets start with importing our libraries...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "# Import the matplotlib library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 read in the titanic dataset \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore our data to get a feel of what we are dealing with. Remember this is typically the first step of the process, if you do not understand your data, then you will not be able to predict with your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we must group the dataset by Pclass and Survived to gather the total count\n",
    "group = titanic_data.groupby(['pclass', 'survived'])\n",
    "pclass_survived = group.size().unstack()\n",
    "\n",
    "\n",
    "# Creating a histogram of age by survival\n",
    "hist = px.histogram(titanic_data,x = \"age\", opacity = 0.7, color = \"survived\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will demonstrate how I explored the data.The first thing you will notice is that I created two list:\n",
    "\n",
    "- categorical columns \n",
    "- numerical columns\n",
    "\n",
    "I do this, to make it easier for me to access columns from these groups and if I need to apply any transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"name\",\"sex\",\"cabin\",\"embarked\", \"home.dest\"]\n",
    "numerical_columns = [\"pclass\",\"survived\",\"age\",\"sibsp\",\"parch\",\"ticket\",\"fare\",\"boat\",\"body\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will look at the values from my categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"For column {}, the values are: \\n{} \\n\".format(column, titanic_data[column].value_counts()))\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look at how our numerical values are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in numerical_columns:\n",
    "    if col in [\"pclass\",\"survived\",\"sibsp\",\"parch\"]:\n",
    "        titanic_data.hist(column=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to start preparing our data. Here we will transform columns or clean up the data before we begin to feature engineer any new columns. \n",
    "\n",
    "Lets start with replacing our good ole friend the \"?\", so that we can decide how to replace missing values later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic_data.replace({'?': None})\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets count how many missing values we currently have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the step below we can see where I use the list of numerical columns to convert them all to numeric. You could have typed each individual column out, but this way you save time and can focus at the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns to numeric\n",
    "titanic_data[numerical_columns] = titanic_data[numerical_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step I shorten the cabin values to only the cabin letter and not the number. I am doing this to make our next steps easier, but we are losing information that could be important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data[\"cabin\"] = titanic_data[\"cabin\"].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in our previous lesson, Feature engineering is used to enhance our data to draw more insights. Here we will transform stings to numbers, potentially remove missing data, one hot encode data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding cabin\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 8}\n",
    "titanic_data[\"cabin\"] = titanic_data[\"cabin\"].map(deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding sex\n",
    "titanic_data = pd.get_dummies(titanic_data,columns= [\"sex\"], prefix=\"gender\")\n",
    "titanic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below I am implementing a feature engineering technique called **target mean encoding**. We will only glance at the code, but I wanted to give you a demonstration of more complex techniques that are used in industry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = titanic_data[\"survived\"].mean()\n",
    "embarked_agg = titanic_data.groupby(\"embarked\")[\"survived\"].agg(['count','mean'])\n",
    "counts = embarked_agg['count']\n",
    "means = embarked_agg['mean']\n",
    "target_mean = (counts * means + 100 * means)/(counts + 100)\n",
    "titanic_data[\"embarked\"] = titanic_data[\"embarked\"].map(target_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets deal with our missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above we have alot of missing values. Our dataset has about 1309 values, and we have cabin and body with more than 1000 values missing. It is here where we can validate if dropping values or imputing will make a difference in our final results. In the cell below, add or remove columns you believe will affect our model due to missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will drop columns we deem unnecessary. Remember this spot as we will come back \n",
    "titanic_data = titanic_data.drop(columns=[\"name\",\"boat\",\"home.dest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed columns that we have deemed unnecessary, lets fill in values using one of the following:\n",
    "\n",
    "- **mean**: replace missing values using the mean along each column. Can only be used with numeric data.\n",
    "\n",
    "- **median**: replace missing values using the median along each column. Can only be used with numeric data.\n",
    "\n",
    "- **most_frequent**: replace missing using the most frequent value along each column. Can be used with strings or numeric data. If there is more than one such value, only the smallest is returned.\n",
    "\n",
    "- **constant**:  replace missing values with fill_value. Can be used with strings or numeric data.\n",
    "\n",
    "We will be using the `SimpleImputer` method from the sklearn library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# specify method below after strategy=. Mean will be the default value \n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "imp.fit(titanic_data)\n",
    "titanic_data_final = imp.transform(titanic_data)\n",
    "titanic_data_final = pd.DataFrame(titanic_data_final, columns=titanic_data.columns)\n",
    "\n",
    "# Create a copy for regression \n",
    "titanic_data_reg = titanic_data_final\n",
    "\n",
    "titanic_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the cabin value if we did not drop it\n",
    "if \"cabin\" in titanic_data.columns:\n",
    "    titanic_data_final['cabin'] = round(titanic_data_final['cabin'])\n",
    "    titanic_data_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We went over all of the above to emphasize that without good data, we do not have a good model. All of the above is part of the modeling process. \n",
    "\n",
    "Now that we have our **final titanic  dataset** ready we can now approach the steps to model our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Modeling\n",
    "As mentioned from the lecture we have:\n",
    "\n",
    "- Unsupervised Models\n",
    "    - Clustering\n",
    "    - Dimensionality Reduction\n",
    "- Supervised Models\n",
    "    - Regression\n",
    "    - Classification\n",
    "\n",
    "We are focusing on the supervised models.\n",
    "\n",
    "**Classification**: Models are used to classify your target variable. Such as, predict what color my shirt is, or predict if a transaction is fradualent or not. Classification is used to determine a label\n",
    "\n",
    "**Regression**: Models are used to predict values. Such as Predict the stock price for Apple tomorrow, or predict my yearly income for next year. \n",
    "\n",
    "Each both have various specific models under each of them. A few of them are Neural Networks, LSTMS, RandomForrest, XGBoost, DecesionTrees, PCA, K-Means and various others. All these model have the advantages, disadvantages, and specific uses, but we will go over these in another lesson. If you would like to get a head start, you can take a look at the [sklearn documentation](https://scikit-learn.org/stable/user_guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to remove our value that we aim to predict. We do this because then the model will have no way to know what we are asking of it. If we did not specify our target variable, it would be similiar to expecting ice cream, without asking for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = titanic_data_final[\"survived\"]\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After specifying the target variable, we now drop it from the titanic_daata_final, so then we can have a dataset of just our features. What are features? \n",
    "\n",
    "**Features:** Measurable values to be analyzed. \n",
    "\n",
    "An easier way to understand features is to imagine them as the inputs(columns) to an algorithm that helps make the decisions or path to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = titanic_data_final.drop('survived', axis = 1)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check what could be good features\n",
    "Now that we have our features we could use modeling to help us decide which features to use in our final model. We will not go over the code below in detail, but we will use the graph to see what might be good features to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_weights = model.feature_importances_\n",
    "feature_weights\n",
    "\n",
    "# Show top 5 features \n",
    "indices = np.argsort(feature_weights)[::-1]\n",
    "columns = X_train.columns.values[indices[:5]]\n",
    "values = feature_weights[indices][:5]\n",
    "\n",
    "# Creat the plot\n",
    "fig = plt.figure(figsize=(9, 5))\n",
    "plt.title(\"Normalized Weights for First Five Most Predictive Features\", fontsize=16)\n",
    "plt.bar(np.arange(5), values, width=0.6, align=\"center\", color='#00A000', \\\n",
    "       label=\"Feature Weight\")\n",
    "plt.bar(np.arange(5) - 0.3, np.cumsum(values), width=0.2, align=\"center\", color='#00A0A0', \\\n",
    "       label=\"Cumulative Feature Weight\")\n",
    "plt.xticks(np.arange(5), columns)\n",
    "plt.xlim((-0.5, 4.5))\n",
    "plt.ylabel(\"Weight\", fontsize=12)\n",
    "plt.xlabel(\"Feature\", fontsize=12)\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test\n",
    "Before we submit out featres and target to a model, we first need to split our data into a test set and a training set. We split our data into test/train, because if we were to train our model with the complete dataset, how could we test our model? How could we know if our model is better than just guessing. \n",
    "\n",
    "By splitting the data we are providing a system of checks and balances, so that if we were to use this model in real life, we could verify our model to more than what is included in our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `train_test_split` method from the sklearn library to split our data 70% training and 30% testing. You can play with this to see how your results vary. Just change the **test_size** input to a decimal value from .1-.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets take a quick look at our train features values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets take a quick look at our train target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model\n",
    "\n",
    "We are finally at the step to creating our model. As this will be your second time viewing a model, we will mainly use the default settings. Models typically have a variety of levers that can be used, but we will cover this in another lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the classifier from sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# Define the classifier, and fit it to the data. Here we are creating a variable type of the DecisionTreeClassifier\n",
    "# that we will use to perform actions with. \n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to see all of the actions that you can take with [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) follow the link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "We will now train our model. Taining our model will use our training set created from `train_test_split`. This step can be viewed as teaching our model. The model than stores memory as weights, which will then be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a graph of how are model made decisions. As you can see it made lots of decisions based off of the data we provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict using your model\n",
    "Now we will ask our model to guess values from our testing set. The model has not seen these values, so it is a good test to see how we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check our results\n",
    "\n",
    "Remember, with classification models we are predicting what category an observation falls into. To judge the accuracy of our model we have the following metrics available to us:\n",
    "- accuracy\n",
    "- precision\n",
    "- recall \n",
    "\n",
    "We will focus on precision, recall, and accuracy. One way to calculate these metrics is to use the values from the confusion matrix. Lets start by importing metrics from the `sklean` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets quickly look at our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the accuracy of your predictions\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** How do you think we did?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double Click Here)** Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuraccy \n",
    "Lets dive into our next lesson, model accuracy. Lets start by asking a question..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this value tell us about our model?\n",
    "   - It tells how well our model was able to predict the results\n",
    "   - Our model was able to accurately predict whether or not someone survived the titanic 74% of the time\n",
    "   - How many passagers does that translate into?\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the number of accurate predictions in a variable\n",
    "pass_in_test = y_test.count()\n",
    "print('The number of passengers in our test dataset was', pass_in_test)\n",
    "print('The number of passengers which our model accurately predicted would survive/not survive was', test_accuracy*pass_in_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dive deeper..\n",
    "\n",
    "- Out of the passengers who actually survived, how many did our model predict would survived?\n",
    "- Out of the passenger who actually did not survive, how many did our model predict would not survive?\n",
    "\n",
    "It is now time to look at our confusion matrix to get these answers...\n",
    "\n",
    "![confusionmatrix](confusion_matrix.png \"confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets generate our own confusion matrix below from the `sklearn.metrics` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_confusion_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(titanic_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the confusion matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the confusion matrix\n",
    "plt.figure(figsize = (5,3))\n",
    "sns.heatmap(titanic_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets jump into metrics that we saw before, but now we will shed some light into how they are calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Precision:***\n",
    "- From our confusion matrix we can see that our model predicted that 169 passengers survived, however out of these..\n",
    "    - We predicted 51 false positives (top right result of our matrix)\n",
    "    - Our precision was 0.7 (TP/(TP+FP))\n",
    "    - Note that this value is lower than our accuracy. We can say that our model is not actually performing as well as we thought\n",
    "    \n",
    "***Recall:***\n",
    "- Note that our model predicted that 51 passengers would not survive who actually survived. (lower left result of our matrix)\n",
    "    - Depending on the context of our problem our predicitive models can't miss positive results. Specially true in the case of cancer diagnosis for example\n",
    "    - For this reason we measure Recall, the ratio of positive values predicted vs the actual number of positive values in our test dataset\n",
    "    - The goal in this case is to minimize the number of false negative results (the number of cases in which the model incorrectly predicted negative result)\n",
    "    - In the case of the titanic the recall value is 0.7 (TP/(TP+FN))\n",
    "\n",
    "Sklearn also provides a very handy way to quickly calculate all of these values using the `classification_report` method, show below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets tie everything together and use the accuracy metrics we used before to see how we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "train_accuracy_balanced = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = balanced_accuracy_score(y_test, y_test_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "train_recall = recall_score(y_train, y_train_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "\n",
    "print('The training accuracy is {}%'.format(train_accuracy*100))\n",
    "print('The training precision is {}%'.format(train_precision*100))\n",
    "print('The training recall is {}%'.format(train_recall*100))\n",
    "print('The test accuracy is {}%'.format(test_accuracy * 100))\n",
    "print('The test precision is {}%'.format(test_precision * 100))\n",
    "print('The test recall is {}%'.format(test_recall * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** If you had to choose one accuracy metric to judge your model, which would you choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Double Click Here) Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, with regression models we are trying to predict a numerical value. How could we validate if our predicition of said value is correct? Could we look at the numbers and see if they match? Could we look at the difference of the values?\n",
    "\n",
    "**Exercise 5:** If you were going to judge a regression model for accuracy, how would you do it? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Double Click Here)** Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets dive into the two ways we can validate our regression models. \n",
    "\n",
    "- **Mean absolute error (MAE)**: The MAE method is very simple. Lets say I predicted that DogeCoin was going to be 50 dollars tomorrow, and the actual value was 38. My MAE would 50 (Predicted) - 38 (actual) = 12. MAE is simply the difference between what you predicted and what is the actual value. \n",
    "\n",
    "\n",
    "- **Mean squared error (MSE)**: MSE is exactly like MAE, the only difference is after we subtract the value we square that result, so we would then have, (50 (Predicted) - 38 (actual)) = 144. MSE allows for larger errors to have a larger impact. This could be useful when there are extremely large values in your data that overcast the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now go over a quick implementation. We will change our prediction of the titanic dataset from survived, to predicting the value of the ticket for passengers. We will follow the same steps above from modeling and build a quick regression model to validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our Regression model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "# Build our target and features data\n",
    "reg_target = titanic_data_reg[\"fare\"]\n",
    "reg_features = titanic_data_reg.drop(\"fare\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reg_features, reg_target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create our model and train in on the training set\n",
    "reg_model = DecisionTreeRegressor()\n",
    "reg_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using our regression model\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate our regression model using MAE and MSE\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"The mean absolute Error is: {}\".format(mean_absolute_error(y_test, y_test_pred)))\n",
    "print(\"The mean Squared Error is: {}\".format(mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what can we interpret from these results? Using the mean absolute error we were about 32 British pounds off, not too bad. With the Mean Squared error we were about 3457 British pounds off, not to good. \n",
    "\n",
    "So how do we know which error metric we should be using? Picking between the MAE and the MSE comes down to the application. Typically if your data has outliers that you want to account for, you would use MSE. If your data is not senstive to outliers you can stick to MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations Future Data Scientist/Machine Learning Engineer! \n",
    "\n",
    "## You've now added many awesome techniques to your toolbox. \n",
    "\n",
    "### Congrats on your final lesson!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
